{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: langchain in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (0.2.12)\n",
      "Requirement already satisfied: openai in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (1.38.0)\n",
      "Collecting duckduckgo-search\n",
      "  Obtaining dependency information for duckduckgo-search from https://files.pythonhosted.org/packages/f5/67/b1eb59a859717043b605eb16d4f3afe46ec3614804ac0fbe594339667866/duckduckgo_search-6.2.11-py3-none-any.whl.metadata\n",
      "  Downloading duckduckgo_search-6.2.11-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pydantic in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (1.10.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from requests) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from requests) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from langchain) (3.8.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from langchain) (0.2.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from langchain) (0.1.96)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\jihoo\\appdata\\roaming\\python\\python311\\site-packages (from openai) (4.12.2)\n",
      "Collecting click>=8.1.7 (from duckduckgo-search)\n",
      "  Obtaining dependency information for click>=8.1.7 from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting primp>=0.6.1 (from duckduckgo-search)\n",
      "  Obtaining dependency information for primp>=0.6.1 from https://files.pythonhosted.org/packages/e6/69/c30564f546dc2c1f118526d2f1dc17d8440b2fe2c574018333881450a860/primp-0.6.1-cp38-abi3-win_amd64.whl.metadata\n",
      "  Downloading primp-0.6.1-cp38-abi3-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jihoo\\appdata\\roaming\\python\\python311\\site-packages (from click>=8.1.7->duckduckgo-search) (0.4.6)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\jihoo\\appdata\\roaming\\python\\python311\\site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (2.1)\n",
      "Downloading duckduckgo_search-6.2.11-py3-none-any.whl (27 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB ? eta 0:00:00\n",
      "Downloading primp-0.6.1-cp38-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.9/2.7 MB 28.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.3/2.7 MB 29.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.3/2.7 MB 18.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.4/2.7 MB 15.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.6/2.7 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 10.9 MB/s eta 0:00:00\n",
      "Installing collected packages: primp, click, duckduckgo-search\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.0.4\n",
      "    Uninstalling click-8.0.4:\n",
      "      Successfully uninstalled click-8.0.4\n",
      "Successfully installed click-8.1.7 duckduckgo-search-6.2.11 primp-0.6.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n",
      "spyder 5.4.3 requires jedi<0.19.0,>=0.17.2, but you have jedi 0.19.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 langchain openai duckduckgo-search pydantic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wikipedia\n",
      "  Using cached wikipedia-1.4.0-py3-none-any.whl\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from wikipedia) (4.12.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from wikipedia) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2023.7.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jihoo\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.4)\n",
      "Installing collected packages: wikipedia\n",
      "Successfully installed wikipedia-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wikipedia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals. Such machines may be called AIs.\n",
      "Some high-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT, Apple Intelligence, and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"\n",
      "The various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics. General intelligence—the ability to complete any task performable by a human on an at least equal level—is among the field's long-term goals. To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics. AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.\n",
      "Artificial intelligence was founded as an academic discipline in 1956, and the field went through multiple cycles of optimism, followed by periods of disappointment and loss of funding, known as AI winter. Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques. This growth accelerated further after 2017 with the transformer architecture, and by the early 2020s hundreds of billions of dollars were being invested in AI (known as the \"AI boom\"). The widespread use of AI in the 21st century exposed several unintended consequences and harms in the present and raised concerns about its risks and the long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n"
     ]
    }
   ],
   "source": [
    "import wikipedia\n",
    "print(wikipedia.summary(\"Artificial intelligence\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `WikipediaSearch` with `{'query': 'XZ backdoor'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mPage: XZ Utils backdoor\n",
      "Summary: In February 2024, a malicious backdoor was introduced to the Linux utility xz within the liblzma library in versions 5.6.0 and 5.6.1 by an account using the name \"Jia Tan\". The backdoor gives an attacker who possesses a specific Ed448 private key remote code execution capabilities on the affected Linux system. The issue has been given the Common Vulnerabilities and Exposures number CVE-2024-3094 and has been assigned a CVSS score of 10.0, the highest possible score.\n",
      "While xz is commonly present in most Linux distributions, at the time of discovery the backdoored version had not yet been widely deployed to production systems, but was present in development versions of major distributions. The backdoor was discovered by the software developer Andres Freund, who announced his findings on 29 March 2024.\n",
      "\n",
      "Page: XZ Utils\n",
      "Summary: XZ Utils (previously LZMA Utils) is a set of free software command-line lossless data compressors, including the programs lzma and xz, for Unix-like operating systems and, from version 5.0 onwards, Microsoft Windows. For compression/decompression the Lempel–Ziv–Markov chain algorithm (LZMA) is used. XZ Utils started as a Unix port of Igor Pavlov's LZMA-SDK that has been adapted to fit seamlessly into Unix environments and their usual structure and behavior.\n",
      "\n",
      "Page: Backdoor (computing)\n",
      "Summary: A backdoor is a typically covert method of bypassing normal authentication or encryption in a computer, product, embedded device (e.g. a home router), or its embodiment (e.g. part of a cryptosystem, algorithm, chipset, or even a \"homunculus computer\"—a tiny computer-within-a-computer such as that found in Intel's AMT technology). Backdoors are most often used for securing remote access to a computer, or obtaining access to plaintext in cryptosystems. From there it may be used to gain access to privileged information like passwords, corrupt or delete data on hard drives, or transfer information within autoschediastic networks.\n",
      "A backdoor may take the form of a hidden part of a program, a separate program (e.g. Back Orifice may subvert the system through a rootkit), code in the firmware of the hardware, or parts of an operating system such as Windows. Trojan horses can be used to create vulnerabilities in a device. A Trojan horse may appear to be an entirely legitimate program, but when executed, it triggers an activity that may install a backdoor. Although some are secretly installed, other backdoors are deliberate and widely known. These kinds of backdoors have \"legitimate\" uses such as providing the manufacturer with a way to restore user passwords.\n",
      "Many systems that store information within the cloud fail to create accurate security measures. If many systems are connected within the cloud, hackers can gain access to all other platforms through the most vulnerable system. Default passwords (or other default credentials) can function as backdoors if they are not changed by the user. Some debugging features can also act as backdoors if they are not removed in the release version. In 1993, the United States government attempted to deploy an encryption system, the Clipper chip, with an explicit backdoor for law enforcement and national security access. The chip was unsuccessful.\n",
      "Recent proposals to counter backdoors include creating a database of backdoors' triggers and then using neural networks to detect them.\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `SaveToTextFile` with `{'content': 'In February 2024, a malicious backdoor was introduced to the Linux utility xz within the liblzma library in versions 5.6.0 and 5.6.1 by an account using the name \"Jia Tan\". The backdoor gives an attacker who possesses a specific Ed448 private key remote code execution capabilities on the affected Linux system. The issue has been given the Common Vulnerabilities and Exposures number CVE-2024-3094 and has been assigned a CVSS score of 10.0, the highest possible score.\\nWhile xz is commonly present in most Linux distributions, at the time of discovery the backdoored version had not yet been widely deployed to production systems, but was present in development versions of major distributions. The backdoor was discovered by the software developer Andres Freund, who announced his findings on 29 March 2024.', 'filename': 'XZ_Backdoor_Info.txt'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m연구 내용이 XZ_Backdoor_Info.txt에 저장되었습니다.\u001b[0m\u001b[32;1m\u001b[1;3mThe information about the XZ backdoor has been successfully saved in a text file named \"XZ_Backdoor_Info.txt\". If you need further assistance, feel free to ask!\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '\\nSearch XZ backdoor on Wikipedia first, \\nif no results, search on DuckDuckGo. \\nif there is a result scrap it ans save as .txt file.\\n',\n",
       " 'output': 'The information about the XZ backdoor has been successfully saved in a text file named \"XZ_Backdoor_Info.txt\". If you need further assistance, feel free to ask!'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from typing import Type\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools import BaseTool\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.utilities import DuckDuckGoSearchAPIWrapper, WikipediaAPIWrapper\n",
    "from bs4 import BeautifulSoup  # 웹 스크래핑을 위한 BeautifulSoup\n",
    "\n",
    "# OpenAI 언어 모델 초기화\n",
    "llm = ChatOpenAI(temperature=0.1, model_name=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "# Wikipedia 검색 도구\n",
    "class WikipediaSearchToolArgsSchema(BaseModel):\n",
    "    query: str = Field(description=\"Wikipedia에 대한 검색 쿼리. 예: '양자 물리학'\")\n",
    "\n",
    "class WikipediaSearchTool(BaseTool):\n",
    "    name = \"WikipediaSearch\"\n",
    "    description = \"주어진 쿼리와 관련된 정보를 Wikipedia에서 검색합니다.\"\n",
    "    \n",
    "    args_schema: Type[WikipediaSearchToolArgsSchema] = WikipediaSearchToolArgsSchema\n",
    "\n",
    "    def _run(self, query):\n",
    "        wiki = WikipediaAPIWrapper()\n",
    "        return wiki.run(query)\n",
    "\n",
    "# DuckDuckGo 검색 도구\n",
    "class DuckDuckGoSearchToolArgsSchema(BaseModel):\n",
    "    query: str = Field(description=\"DuckDuckGo에서 검색할 쿼리입니다.\")\n",
    "\n",
    "class DuckDuckGoSearchTool(BaseTool):\n",
    "    name = \"DuckDuckGoSearch\"\n",
    "    description = \"DuckDuckGo에서 정보를 검색합니다.\"\n",
    "    \n",
    "    args_schema: Type[DuckDuckGoSearchToolArgsSchema] = DuckDuckGoSearchToolArgsSchema\n",
    "\n",
    "    def _run(self, query):\n",
    "        ddg = DuckDuckGoSearchAPIWrapper()\n",
    "        return ddg.run(query)\n",
    "\n",
    "# 웹 스크래핑 도구\n",
    "class WebScrapeArgsSchema(BaseModel):\n",
    "    url: str = Field(description=\"텍스트를 스크랩할 웹사이트의 URL입니다.\")\n",
    "\n",
    "class WebScrapeTool(BaseTool):\n",
    "    name = \"WebScrape\"\n",
    "    description = \"주어진 URL에서 텍스트를 스크랩하고 추출합니다.\"\n",
    "    \n",
    "    args_schema: Type[WebScrapeArgsSchema] = WebScrapeArgsSchema\n",
    "\n",
    "    def _run(self, url):\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        paragraphs = soup.find_all('p')\n",
    "        content = '\\n'.join([p.get_text() for p in paragraphs])\n",
    "        return content\n",
    "\n",
    "# 연구 결과를 .txt 파일에 저장하는 도구\n",
    "class SaveToTextFileArgsSchema(BaseModel):\n",
    "    content: str = Field(description=\"저장할 내용.\")\n",
    "    filename: str = Field(default=\"research_output.txt\", description=\"연구 결과를 저장할 파일 이름.\")\n",
    "\n",
    "class SaveToTextFileTool(BaseTool):\n",
    "    name = \"SaveToTextFile\"\n",
    "    description = \".txt 파일에 연구 결과를 저장합니다.\"\n",
    "    \n",
    "    args_schema: Type[SaveToTextFileArgsSchema] = SaveToTextFileArgsSchema\n",
    "\n",
    "    def _run(self, content, filename):\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write(content)\n",
    "        return f\"연구 내용이 {filename}에 저장되었습니다.\"\n",
    "\n",
    "# 도구를 포함한 에이전트 초기화\n",
    "agent = initialize_agent(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    agent=AgentType.OPENAI_FUNCTIONS,\n",
    "    handle_parsing_errors=True,\n",
    "    tools=[\n",
    "        WikipediaSearchTool(),\n",
    "        DuckDuckGoSearchTool(),\n",
    "        WebScrapeTool(),\n",
    "        SaveToTextFileTool()\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 연구 쿼리 실행\n",
    "prompt = \"\"\"\n",
    "Search XZ backdoor on Wikipedia first, \n",
    "if no results, search on DuckDuckGo. \n",
    "if there is a result scrap it ans save as .txt file.\n",
    "\"\"\"\n",
    "\n",
    "agent.invoke(prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
