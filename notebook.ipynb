{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "faiss.write_index(vectorstore.index, \"./.cache/faiss_index\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jihoo\\AppData\\Local\\Temp\\ipykernel_34492\\1214550821.py:14: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  llm = ChatOpenAI()\n",
      "C:\\Users\\jihoo\\AppData\\Local\\Temp\\ipykernel_34492\\1214550821.py:27: LangChainDeprecationWarning: The class `UnstructuredFileLoader` was deprecated in LangChain 0.2.8 and will be removed in 1.0. An updated version of the class exists in the langchain-unstructured package and should be used instead. To use it run `pip install -U langchain-unstructured` and import as `from langchain_unstructured import UnstructuredLoader`.\n",
      "  loader = UnstructuredFileLoader(\"./files/example.txt\")\n",
      "C:\\Users\\jihoo\\AppData\\Local\\Temp\\ipykernel_34492\\1214550821.py:31: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  embeddings = OpenAIEmbeddings()\n",
      "C:\\Users\\jihoo\\AppData\\Local\\Temp\\ipykernel_34492\\1214550821.py:51: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
      "C:\\Users\\jihoo\\AppData\\Local\\Temp\\ipykernel_34492\\1214550821.py:54: LangChainDeprecationWarning: This class is deprecated. Use the `create_stuff_documents_chain` constructor instead. See migration guide here: https://python.langchain.com/v0.2/docs/versions/migrating_chains/stuff_docs_chain/\n",
      "  combine_documents_chain = StuffDocumentsChain(llm_chain=llm_chain)\n",
      "C:\\Users\\jihoo\\AppData\\Local\\Temp\\ipykernel_34492\\1214550821.py:57: LangChainDeprecationWarning: This class is deprecated. Use the `create_retrieval_chain` constructor instead. See migration guide here: https://python.langchain.com/v0.2/docs/versions/migrating_chains/retrieval_qa/\n",
      "  chain = RetrievalQA(combine_documents_chain=combine_documents_chain, retriever=retriever, memory=memory)\n",
      "C:\\Users\\jihoo\\AppData\\Local\\Temp\\ipykernel_34492\\1214550821.py:69: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  response = chain.run(question)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Is Aaronson guilty?\n",
      "Answer: What is the significance of Winston's moment of weakness when he cries out for Julia in the passage?\n",
      "\n",
      "Question: What message did he write in the table?\n",
      "Answer: What task did Winston set out to do deliberately on the plank bed with the slate on his knees? \n",
      "\n",
      "Winston set out to re-educate himself by writing down his thoughts and beliefs, such as \"FREEDOM IS SLAVERY\" and \"TWO AND TWO MAKE FIVE,\" in order to align his thinking with that of the Party.\n",
      "\n",
      "Question: Who is Julia?\n",
      "Answer: Who does Winston betray in a moment of weakness and desperation in this passage?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.chains import RetrievalQA, StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import faiss\n",
    "\n",
    "# Language Model\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# 캐시 디렉토리 설정\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "# 텍스트 분할기 설정\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "# 문서 로드 및 분할\n",
    "loader = UnstructuredFileLoader(\"./files/example.txt\")\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "# 임베딩 설정\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(embeddings, cache_dir)\n",
    "\n",
    "# FAISS 벡터 스토어 생성 및 저장\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "faiss.write_index(vectorstore.index, \"./.cache/faiss_index\")\n",
    "\n",
    "# Retriever 생성\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# ConversationBufferMemory 추가\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=\"Using the context below, answer the following question: {context}\"\n",
    ")\n",
    "\n",
    "# LLMChain 생성\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# StuffDocumentsChain을 사용하여 문서 결합 체인 생성\n",
    "combine_documents_chain = StuffDocumentsChain(llm_chain=llm_chain)\n",
    "\n",
    "# RetrievalQA 체인 생성\n",
    "chain = RetrievalQA(combine_documents_chain=combine_documents_chain, retriever=retriever, memory=memory)\n",
    "\n",
    "# 체인 실행\n",
    "# 질문 목록\n",
    "questions = [\n",
    "    \"Is Aaronson guilty?\",\n",
    "    \"What message did he write in the table?\",\n",
    "    \"Who is Julia?\"\n",
    "]\n",
    "\n",
    "# 질문에 대한 답변을 순차적으로 요청\n",
    "for question in questions:\n",
    "    response = chain.run(question)\n",
    "    print(f\"Question: {question}\\nAnswer: {response}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
